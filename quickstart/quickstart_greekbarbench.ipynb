{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMkCdLiWDiNN"
      },
      "source": [
        "# This is a *quickstart* notebook for the benchmark **GreekBarBench** and the accompanying judge meta-evaluation benchmark **GBB-JME**.\n",
        "\n",
        "This notebook is part of the research presented in the paper:\n",
        "\n",
        "***GreekBarBench: A Challenging Benchmark for Free-Text Legal Reasoning and Citations***\n",
        "\n",
        "The code is available in <https://github.com/nlpaueb/greek-bar-bench>.\n",
        "\n",
        "The dataset is available in <https://huggingface.co/datasets/AUEB-NLP/greek-bar-bench>.\n",
        "\n",
        "Please cite this paper using the following BibTeX entry:\n",
        "\n",
        "```bibtex\n",
        "@misc{chlapanis2025greekbarbenchchallengingbenchmarkfreetext,\n",
        "      title={GreekBarBench: A Challenging Benchmark for Free-Text Legal Reasoning and Citations},\n",
        "      author={Odysseas S. Chlapanis and Dimitrios Galanis and Nikolaos Aletras and Ion Androutsopoulos},\n",
        "      year={2025},\n",
        "      eprint={2505.17267},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.CL},\n",
        "      url={https://arxiv.org/abs/2505.17267},\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVeUQnWunOo8"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) 2025 NLP AUEB\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWSB8OQvlw5E"
      },
      "source": [
        "<small>\n",
        "The implementation for the SPA calculation is taken as is from:\n",
        "</small>\n",
        "\n",
        "https://github.com/google-research/mt-metrics-eval/blob/main/mt_metrics_eval/pce.py\n",
        "\n",
        "<small>\n",
        "Based on the method described in the following paper:\n",
        "\n",
        "*Brian Thompson, Nitika Mathur, Daniel Deutsch, and Huda Khayrallah. 2024. Improving Statistical Significance in Human Evaluation of Automatic Metrics via Soft Pairwise Accuracy. In Proceedings of the Ninth Conference on Machine Translation, pages 1222–1234, Miami, Florida, USA. Association for Computational Linguistics.*\n",
        "</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eobzz1y0K6XV"
      },
      "source": [
        "## Upgrade datasets\n",
        "\n",
        "We need to upgrade the `datasets` library for compatibility and to avoid path issues in Google Colab.\n",
        "\n",
        "**Important:** After this cell runs, you **must** restart the runtime (`Runtime > Restart runtime`) before proceeding. Then, you can run the rest of the notebook (`Runtime > Run all`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jps-ODoVKtUO"
      },
      "outputs": [],
      "source": [
        "! pip install -q --upgrade datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkwaDXYWGDGV"
      },
      "source": [
        "## Initialize parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Zf1BlQzOGGmi"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gemini-2.0-flash-001\"\n",
        "JUDGE = \"gpt-4.1-2025-04-14\"\n",
        "JUDGE_TYPE = \"span\"\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR_API_KEY\"\n",
        "GOOGLE_API_KEY = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0GbaTbhhJcCO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-caqPGYiLdC2"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279,
          "referenced_widgets": [
            "64d081b6e1f94b54a2bd9c76cb735884",
            "1fe837e49c8c41cd95d3a05e449b7f7a",
            "b247b600508245a3a39628ff97cf6a59",
            "186cae6964374d02bb11c94a5ff3e5bd",
            "2a6f434d7eda47d79b7f7804154b9b07",
            "a1049d1de8654842893bb90d64517eb1",
            "444428351c5745bdaf08e6befdb6c3ce",
            "cdccff244681431581b4dbebc0b3f6dc",
            "99732519afeb44999a58d0306485fa47",
            "6968ca52ae134781b5324e4213a23eac",
            "4cf2416ef066433c8c1d5a29caa33f7a",
            "505d83a88589498e9872aa1c43bc7fa5",
            "7e87fabea6284db6af2d847fcdd80aae",
            "6d1cefe241954241806f58cc4628ef71",
            "2636ce18d084441ead825c9ba15bfad8",
            "6a67111c197f4d36837482fcd4781856",
            "bf63207595864d87b64b013660b51aa1",
            "1be3fb6ca88e4bc5b798161cd6db64a6",
            "6b6ec103022a412a8c40a3b4951d638d",
            "02f6f786916e48368dcf04d97fc5f5d5",
            "4b612c1130e84acfab646d679338c175",
            "653de683a9434b8089bf43fb16f6ea64",
            "e599952fa7774330a1c6b804c0f9eb73",
            "282ebaf88445402e8ad687142faf4530",
            "25ca18d7ae9540838d150d69c4516c67",
            "2a6a0ce78acb4e6398a70b9a4375e603",
            "859f3bbfcc2c40349b9cabd04fcfc9f6",
            "a665ed5a933d49b38643ca70aba528c1",
            "aba6a08f5551468da21c7be8076e8a9e",
            "bfa1106e644645a5b44b1298fa1a15ad",
            "104524f01b9d4a91a72b8b793a18ca37",
            "62b6e2505858452bba73c844a01f01ac",
            "0210c050cf2f421f94bb82954d35320e",
            "b6d710b119bb43e292ad888f2e75bad8",
            "8dafd2102440459eac5aac6162bdc833",
            "10de49069aa646b9978d77098888c667",
            "cbbde9167054420ab6bf01ed3f4016df",
            "5af195ff975647d3af6a7f27af74981e",
            "1c2a71e967da4a31b028a5bacd7aeccb",
            "637ee256b0b44391965ebf2cef24b913",
            "c7eb9996355e47bc9ad9ed88e0c43607",
            "0f3bef95f2dd486a8a722433e5aee12c",
            "a01709c4c9bc4ec0ac6230a821fb5628",
            "04142b7c974b40e79cb0d0f057331657",
            "52f45b9716a045beb3bbbb920f966f18",
            "85bd7728737640d397125452a866977b",
            "a2eb79ed13ba458ebe3a42353ceb26bc",
            "18f4a8ebe82d44f0a5c5f455c570c0d0",
            "b2fb5de0e07f4951968cdd6bbb90fbfe",
            "1d916953a94a47d1afa5f4288dfea2de",
            "b472236705574f2cb3b93600a9075cfe",
            "6a827bcceb3a46158a778c0a4e73b572",
            "712e9233789e40e6bbb222e215e05724",
            "2e031c3b1a1e42cd882338756798672a",
            "fd5b12675a364b0f818a1f68f2cba9ad"
          ]
        },
        "id": "Gc9LNqKODCrZ",
        "outputId": "0e829a3a-ba26-42af-b60c-595ed983fcd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d081b6e1f94b54a2bd9c76cb735884",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/12.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "505d83a88589498e9872aa1c43bc7fa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "greekbarbench.csv:   0%|          | 0.00/42.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e599952fa7774330a1c6b804c0f9eb73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/284 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6d710b119bb43e292ad888f2e75bad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "gbb_jme.csv:   0%|          | 0.00/550k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52f45b9716a045beb3bbbb920f966f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/305 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"AUEB-NLP/greek-bar-bench\"\n",
        "split_name = \"test\"\n",
        "name = \"greekbarbench\"\n",
        "name_jme = \"gbb-jme\"\n",
        "dataset = load_dataset(dataset_name, name=name, split=split_name)\n",
        "\n",
        "dataset_jme = load_dataset(dataset_name, name=name_jme, split=split_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Oxo0MxvEgY8",
        "outputId": "c32a2585-cd67-4469-983b-c3d6e56b5cca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['facts', 'question', 'answer', 'chapters', 'spans', 'area', 'date', 'articles', 'number', 'index'],\n",
              "    num_rows: 284\n",
              "})"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHrWK1rPLW-G",
        "outputId": "354fceeb-8e6d-4512-8649-a169f870b03f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['number', 'model', 'response', 'facts', 'articles', 'analysis', 'avg', 'area', 'date', 'reasoning', 'index'],\n",
              "    num_rows: 305\n",
              "})"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_jme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wfY9EpiLe2x"
      },
      "source": [
        "## Setup OpenAI and Google generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BONty2RfLlSt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "def gpt_prompt(system, prompt):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "    return messages\n",
        "\n",
        "\n",
        "def call_gpt(model, system, prompt):\n",
        "    client = OpenAI()\n",
        "    # Generate response using client.responses\n",
        "    response = client.responses.create(\n",
        "        model=model,\n",
        "        input=gpt_prompt(system, prompt),\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=8192,\n",
        "        top_p=1,\n",
        "    )\n",
        "    # Return the assistant's response text\n",
        "    return response.output[0].content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfIzMlYrgeW",
        "outputId": "6f065c75-703c-4554-b8fa-0c0ea083e94a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Greek Constitution is the fundamental law of Greece that establishes the structure, functions, and principles of the Greek state. It defines the organization of government, the separation of powers, the rights and duties of citizens, and the framework within which laws are made and enforced. The Constitution serves as the supreme legal authority in Greece, meaning that all laws and government actions must comply with its provisions.\n",
            "\n",
            "The current Greek Constitution, often referred to as the Constitution of 1975 (with several subsequent amendments), was adopted after the fall of the military junta in 1974 and the restoration of democracy. It enshrines democratic principles, the rule of law, human rights, and the role of Greece as a parliamentary republic. The Constitution also establishes important institutions such as the Parliament, the Presidency, the Judiciary, and defines Greece's relationship with the European Union.\n",
            "\n",
            "In summary, the Greek Constitution is the foundational legal document that governs the political system and legal order in Greece.\n"
          ]
        }
      ],
      "source": [
        "# # Example usage\n",
        "# result = call_gpt(\"gpt-4.1-mini\", \"\", \"What is the Greek Constitution?\")\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qag0gPRuLlY7"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "\n",
        "def call_gemini(model, system, prompt):\n",
        "    client = genai.Client()\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system),\n",
        "        contents=[prompt]\n",
        "    )\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4AZcYvnrmLs",
        "outputId": "c221033a-1a22-459b-d7e5-9736c4fa4e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Greek Constitution is the supreme law of Greece. It outlines the fundamental principles of the state, the rights and freedoms of its citizens, and the structure and powers of the government. Here's a breakdown of key aspects:\n",
            "\n",
            "*   **Foundation of the Greek State:** It establishes Greece as a parliamentary republic.\n",
            "*   **Fundamental Rights:** It guarantees a wide range of human rights and fundamental freedoms, including freedom of speech, assembly, religion, and the press, as well as protection from discrimination and arbitrary arrest.\n",
            "*   **Separation of Powers:** It divides governmental power among three branches:\n",
            "    *   **Legislative:** The Hellenic Parliament, elected by the people, is responsible for making laws.\n",
            "    *   **Executive:** The President of the Republic, elected by Parliament, is the head of state. The Prime Minister, appointed by the President, is the head of government and leads the cabinet.\n",
            "    *   **Judicial:** The courts are responsible for interpreting and applying the law.\n",
            "*   **Amendment Process:** It provides a specific process for amending the constitution, requiring supermajorities in Parliament.\n",
            "*   **Historical Context:** The current constitution was adopted in 1975, following the end of the military junta. It has been amended several times since then.\n",
            "*   **Key Principles:** These include popular sovereignty, the rule of law, and the protection of human rights.\n"
          ]
        }
      ],
      "source": [
        "# result = call_gemini(\"gemini-2.0-flash\", \"\", \"What is the Greek Constitution?\")\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAPGyovQLlu3"
      },
      "source": [
        "# Evaluate model on **GreekBarBench**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu9_fRH9NwVu"
      },
      "source": [
        "## Prompts for candidates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tgYJJu-5N5VV"
      },
      "outputs": [],
      "source": [
        "candidate_system_prompt = '''You are a legal assistant who answers questions in Greek, focusing on the legal system and the laws of Greece. You analyze your reasoning and respond with well-supported answers and correct references. You only respond in txt format and with only one short paragraph without headings.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fDAhZo8NSSUY"
      },
      "outputs": [],
      "source": [
        "candidate_user_prompt = '''You are given the numbered facts of a legal case, the current relevant legislation of Greece, and a question regarding this case. After carefully reading the entire text, you are to provide a comprehensive answer to the question, analyzing your reasoning. You should answer with references to the relevant legislation using the appropriate abbreviations for the laws (for example, you can say: \"according to article X CC\" to refer to article \"X\" of the Civil Code), where necessary. Additionally, you must provide references to the facts of the case (for example, you can say: \"according to statement Y of the case data\"), where necessary. Answer strictly within the extent of one short paragraph.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyJSpKkcxMqa"
      },
      "source": [
        "## Get user prompt for sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9Zy0Ex5NxQWn"
      },
      "outputs": [],
      "source": [
        "def get_user_prompt(instance, user_prompt):\n",
        "    \"\"\"\n",
        "    Construct a prompt from a dataset sample by combining the user prompt with the facts, question, and legal code chapters of the instance.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"{user_prompt}\\n\"\n",
        "        f\"Case facts:\\n{instance['facts']}\\n\"\n",
        "        f\"Question:\\n{instance['question']}\\n\\n\"\n",
        "        f\"{instance['chapters']}\"\n",
        "    )\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rea1wJ52N4DD"
      },
      "source": [
        "## Generation\n",
        "\n",
        "We are going to select the subset with the `A_2023` date for demonstration purposes. We are going to evaluate the `gemini-2.0-flash` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7a8e6d17327a46cd8c5601fd194b056a",
            "c4b6d8e7ecfd430580575ba2aa9efc33",
            "b55f9f57f0a44d87b9e60ea6aabedf63",
            "3b4c76abeea6471ea09968ca2adcd15b",
            "2626bd6062524a2a824cab71845dc594",
            "829be2e58651453a926ed541551b8974",
            "843863b5c0a34939af2e71e9081dcc2d",
            "c772c8ede78e40a292d8b08be6e4f94b",
            "725c1de061ea438097c6729a027c90e5",
            "d3bd6c3ea64a4314aff196fdb761a5b6",
            "b67007b85c014fd49f6b461b2ca11bef"
          ]
        },
        "id": "QhDkHKfzLrRy",
        "outputId": "4f7aa088-e2a6-473d-a7a3-d3add66095ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a8e6d17327a46cd8c5601fd194b056a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/284 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n"
          ]
        }
      ],
      "source": [
        "subset = dataset.filter(\n",
        "    lambda example: example['date'] == 'A_2023'\n",
        ")\n",
        "print(len(subset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "908Bq_gSNqkR",
        "outputId": "3fbe2733-645f-4988-c280-9ca9437fa09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:\n",
            "Πώς αξιολογείτε από άποψη νομικής βασιμότητας την αγωγή καθ' όλα τα ως άνω αιτήματα και βάσεις της;\n",
            "('Η αγωγή του Α αξιολογείται ως νομικά βάσιμη ως προς την απόδοση του '\n",
            " 'γεωργικού μηχανήματος, δεδομένου ότι, σύμφωνα με τα αναφερόμενα στην αγωγή '\n",
            " '(1-4), στοιχειοθετείται σύμβαση χρησιδανείου κατά το άρθρο 810 ΑΚ, η οποία '\n",
            " 'έληξε, αλλά η εναγόμενη αρνείται την απόδοση του πράγματος. Ωστόσο, όσον '\n",
            " 'αφορά την αξίωση αποζημίωσης για την μη επιστροφή του μηχανήματος (5-6), η '\n",
            " 'νομική της βασιμότητα εξαρτάται από την απόδειξη της υπαιτιότητας της '\n",
            " 'εναγόμενης για την καθυστέρηση και της ζημίας του ενάγοντος, σύμφωνα με τα '\n",
            " 'άρθρα 330, 335, 340 και 343 ΑΚ, καθώς και την ύπαρξη αιτιώδους συνάφειας '\n",
            " 'μεταξύ της καθυστέρησης και της ζημίας. Η ένσταση έλλειψης ενεργητικής '\n",
            " 'νομιμοποίησης (7) θα κριθεί από το δικαστήριο βάσει των αποδείξεων περί του '\n",
            " 'ποιος ήταν ο συμβαλλόμενος στη σύμβαση χρησιδανείου, ενώ ο ισχυρισμός της '\n",
            " 'εναγόμενης περί οικονομικής αδυναμίας (8) δεν αίρει την ευθύνη της για '\n",
            " 'αποζημίωση, εκτός αν αποδειχθεί γεγονός που αίρει την ευθύνη της κατά το '\n",
            " 'άρθρο 342 ΑΚ. Τέλος, η πρόσθετη παρέμβαση του Δ (9) είναι παραδεκτή, εφόσον '\n",
            " 'έχει έννομο συμφέρον, δηλαδή εφόσον η έκβαση της δίκης επηρεάζει τα '\n",
            " \"δικαιώματά του βάσει της σύμβασης πώλησης, κατ' άρθρο 80 ΚΠολΔ.\\n\")\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "\n",
        "instance = subset[0]\n",
        "prompt = get_user_prompt(instance, candidate_user_prompt)\n",
        "# print(prompt)\n",
        "print(f\"Question:\\n{instance['question']}\")\n",
        "answer = call_gemini(MODEL, candidate_system_prompt, prompt)\n",
        "pprint(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "x-u5yVYpzg-M"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "# import json\n",
        "\n",
        "# answers = []\n",
        "\n",
        "# for instance in tqdm(subset, desc=\"Processing dataset\"):\n",
        "#   prompt = get_user_prompt(instance, candidate_user_prompt)\n",
        "#   answer = call_gemini(MODEL, candidate_system_prompt, prompt)\n",
        "#   answers.append(answer)\n",
        "\n",
        "# output_filename = f\"answers_{MODEL}.json\"\n",
        "\n",
        "# try:\n",
        "#     with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "#         json.dump(answers, f, indent=4, ensure_ascii=False)\n",
        "#     print(f\"Successfully saved answers (JSON) to {output_filename}\")\n",
        "# except IOError as e:\n",
        "#     print(f\"Error saving JSON file {output_filename}: {e}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during JSON serialization: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mCasVi60mJA",
        "outputId": "32d7dd51-5ef5-4d0c-cf65-a54cbac45ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded answers (JSON) from answers_gemini-2.0-flash-001.json\n",
            "['Η αγωγή του Α φαίνεται να έχει νομική βάση, ειδικά όσον αφορά το αίτημα για '\n",
            " 'την απόδοση του γεωργικού μηχανήματος, καθώς σύμφωνα με το άρθρο 810 AK, ο '\n",
            " 'χρησάμενος (εν προκειμένω η εταιρεία X) έχει υποχρέωση να αποδώσει το πράγμα '\n",
            " 'μετά τη λήξη της σύμβασης χρησιδανείου, η οποία έληξε στις 12-9-2019 σύμφωνα '\n",
            " 'με το στοιχείο 2 της υπόθεσης. Όσον αφορά την αποζημίωση για τη μη επιστροφή '\n",
            " 'του μηχανήματος, ο ενάγων θα πρέπει να αποδείξει τη ζημία του και την '\n",
            " 'αιτιώδη συνάφεια με την καθυστέρηση της απόδοσης, σύμφωνα με τα άρθρα 298, '\n",
            " '330 και 343 AK, κάτι που φαίνεται να επιχειρεί με την αναφορά στη μίσθωση '\n",
            " 'άλλου μηχανήματος και την απώλεια κερδών, σύμφωνα με το στοιχείο 5. Η '\n",
            " 'ένσταση της εναγόμενης περί έλλειψης ενεργητικής νομιμοποίησης (στοιχείο 7) '\n",
            " 'είναι κρίσιμη και θα κριθεί από το δικαστήριο βάσει των αποδείξεων. Η '\n",
            " 'πρόσθετη παρέμβαση του Δ υπέρ του Α βασίζεται στην από 30.8.2020 σύμβαση '\n",
            " 'πώλησης και έχει έννομο συμφέρον, σύμφωνα με το άρθρο 80 ΚΠολΔ, να '\n",
            " 'υποστηρίξει την αγωγή του Α, καθώς ο Δ θα αποκτήσει το μηχάνημα εφόσον '\n",
            " 'ευδοκιμήσει η αγωγή.\\n',\n",
            " 'Η ένσταση ελλείψεως ενεργητικής νομιμοποιήσεως του ενάγοντος είναι νομικά '\n",
            " 'βάσιμη, καθώς σύμφωνα με το άρθρο 68 ΚΠολΔ, δικαστική προστασία έχει '\n",
            " 'δικαίωμα να ζητήσει όποιος έχει άμεσο έννομο συμφέρον, και αν η σύμβαση '\n",
            " 'χρησιδανείου καταρτίστηκε με τον γιο του ενάγοντος, τότε ο ενάγων δεν έχει '\n",
            " 'άμεσο έννομο συμφέρον. Το βάρος απόδειξης της ένστασης φέρει η εναγόμενη '\n",
            " 'εταιρεία, σύμφωνα με τους γενικούς κανόνες περί αποδείξεως (άρθρο 338 '\n",
            " 'ΚΠολΔ). Ο ισχυρισμός περί αδυναμίας επιστροφής του μηχανήματος λόγω '\n",
            " 'οικονομικής δυσχέρειας δεν απαλλάσσει την εναγόμενη από την υποχρέωση '\n",
            " 'αποζημίωσης του ενάγοντος, καθώς η οικονομική αδυναμία δεν αποτελεί γεγονός '\n",
            " 'για το οποίο δεν έχει ευθύνη, σύμφωνα με το άρθρο 342 AK, και το βάρος '\n",
            " 'αποδείξεως αυτού φέρει η εναγόμενη.\\n']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "input_filename = f\"answers_{MODEL}.json\"\n",
        "\n",
        "loaded_answers_from_json = []\n",
        "\n",
        "try:\n",
        "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
        "        loaded_answers_from_json = json.load(f)\n",
        "\n",
        "    if isinstance(loaded_answers_from_json, list) and all(isinstance(item, str) for item in loaded_answers_from_json):\n",
        "        print(f\"Successfully loaded answers (JSON) from {input_filename}\")\n",
        "    else:\n",
        "        print(f\"Warning: Data loaded from {input_filename} is not a list of strings as expected.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {input_filename} was not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from {input_filename}. The file might be corrupted or not valid JSON.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error reading file {input_filename}: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "answers = loaded_answers_from_json\n",
        "pprint(loaded_answers_from_json[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AANKoctKN0qn"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCnNlPAB1X87"
      },
      "source": [
        "### Evaluation prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxFWHnnb1292"
      },
      "source": [
        "#### Prompt for Simple-Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HLSGGHNVN2bJ"
      },
      "outputs": [],
      "source": [
        "simple_judge_system_prompt = '''You are a legal exam evaluator. You will be given the following:\n",
        "    1. The facts of a case\n",
        "    2. The relevant legislation\n",
        "    3. A question\n",
        "    4. An ideal reference answer\n",
        "    5. An answer for evaluation\n",
        "You will need to evaluate the answer with three scores and an explanation for each. Each score consists of an integer from 1 to 10, with 10 being excellent. The reference answer is considered excellent (10 in all).\n",
        "The Facts Score concerns the facts of the case. If the ideal reference answer mentions certain specific facts from the case, while the answer for evaluation does not mention them, points should be deducted. Similarly, if the answer for evaluation mentions facts that are not useful for the answer, points should also be deducted.\n",
        "The Legislation Score concerns the answer's references to the relevant articles of laws. It is necessary to refer to specific articles of laws. If no such reference is made or if reference is made to wrong articles, points should be deducted from the Legislation Score. Also, points should be deducted if the interpretation of the law is wrong.\n",
        "The Analysis Score concerns a general evaluation of whether the answer for evaluation covered the original question, with correct and valid legal argumentation. Points already evaluated in the above criteria are not assessed here. At this point, the final conclusion of the answer is also evaluated. If the answer for evaluation reaches a wrong conclusion or if it does not mention a critical argument, points should be deducted.\n",
        "Use plain txt text, without markdown.\n",
        "Your answer should follow the template shown below, where X, Y, Z are integers (1-10):\n",
        "Explanation of Facts Score: <your explanation for the score...>\n",
        "Facts Score: X\n",
        "Explanation of Legislation Score: <...>\n",
        "Legislation Score: Y\n",
        "Explanation of Analysis Score: <...>\n",
        "Analysis Score: Z\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-CUt_Q418F7"
      },
      "source": [
        "#### Prompt for Span-Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oEi7ell51-dN"
      },
      "outputs": [],
      "source": [
        "span_judge_system_prompt= '''You are a legal exam evaluator. You will be given the following:\n",
        "    1. The facts of a case\n",
        "    2. The relevant legislation\n",
        "    3. A question\n",
        "    4. An ideal reference answer\n",
        "    5. An answer for evaluation\n",
        "    6. The evaluation spans (json file)\n",
        "The evaluation spans are verbatim excerpts from the text of the ideal reference answer with tags that refer to each of the three scores (facts, articles, analysis). This means that for the evaluation of a score, emphasis should be placed on whether the information from the corresponding span of the ideal reference answer exists in the answer for evaluation, and thus the appropriate score should be given. For example, for the Facts Score (facts), the spans should be present in the answer for evaluation. If spans are not present, it means that very important facts (or laws or analysis) that absolutely must be mentioned are missing. However, points can still be deducted if the answer for evaluation adds facts (or laws or analysis) that are incorrect. There are also important spans, which indicate which parts of the answer are more important for the evaluation.\n",
        "You will need to evaluate the answer with three scores and an explanation for each. Each score consists of an integer from 1 to 10, with 10 being excellent. The reference answer is considered excellent (10 in all).\n",
        "The Facts Score concerns the facts of the case. If the ideal reference answer mentions certain specific facts from the case, while the answer for evaluation does not mention them, points should be deducted. Similarly, if the answer for evaluation mentions facts that are not useful for the answer, points should also be deducted.\n",
        "The Cited Articles Score concerns the answer's references to the relevant articles of laws. It is necessary to refer to specific articles of laws. If no such reference is made or if reference is made to wrong articles, points should be deducted from the Cited Articles Score. Also, points should be deducted if the interpretation of the law is wrong.\n",
        "The Analysis Score concerns a general evaluation of whether the answer for evaluation covered the original question, with correct and valid legal argumentation. Points already evaluated in the above criteria are not assessed here. At this point, the final conclusion of the answer is also evaluated. If the answer for evaluation reaches a wrong conclusion or if it does not mention a critical argument, points should be deducted.\n",
        "Use plain txt text, without markdown.\n",
        "Your answer should follow the template shown below, where X, Y, Z are integers (1-10):\n",
        "Explanation of Facts Score: <your explanation for the score...>\n",
        "Facts Score: X\n",
        "Explanation of Cited Articles Score: <...>\n",
        "Cited Articles Score: Y\n",
        "Explanation of Analysis Score: <...>\n",
        "Analysis Score: Z\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN7Jxa9ZoQ6O"
      },
      "source": [
        "### Evaluation utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n60onq0o26h9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_judgement(text):\n",
        "    \"\"\"\n",
        "    Parses a text containing judgement explanations and scores, extracting\n",
        "    the explanations and the corresponding integer scores using regex.\n",
        "    Ensures that extracted scores are integers between 1 and 10.\n",
        "\n",
        "    Args:\n",
        "        text: The input string containing the judgement breakdown in a specific format.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing six elements in the order:\n",
        "        facts_explanation (str), articles_explanation (str), analysis_explanation (str),\n",
        "        facts (int or None), articles (int or None), analysis (int or None).\n",
        "        Returns empty string for missing explanations and None for missing scores\n",
        "        or scores outside the 1-10 range.\n",
        "    \"\"\"\n",
        "    # Use re.DOTALL flag so '.' matches newline characters within the explanation text\n",
        "    flags = re.DOTALL\n",
        "\n",
        "    # Define patterns for each section.\n",
        "    # Each pattern looks for the Explanation title, captures the text (non-greedily .*?),\n",
        "    # then looks for the corresponding Score title, and captures the digits (\\d+).\n",
        "    # \\s* handles any whitespace (including newlines) around the titles and scores.\n",
        "    # Added \\b around the score title to prevent partial matches like \"Total Score:\"\n",
        "    facts_pattern = r\"Explanation of Facts Score:\\s*(.*?)\\s*\\bFacts Score:\\s*(\\d+)\\b\"\n",
        "    articles_pattern = r\"Explanation of Cited Articles Score:\\s*(.*?)\\s*\\bCited Articles Score:\\s*(\\d+)\\b\"\n",
        "    analysis_pattern = r\"Explanation of Analysis Score:\\s*(.*?)\\s*\\bAnalysis Score:\\s*(\\d+)\\b\"\n",
        "\n",
        "    # Search for each pattern in the text\n",
        "    facts_match = re.search(facts_pattern, text, flags)\n",
        "    articles_match = re.search(articles_pattern, text, flags)\n",
        "    analysis_match = re.search(analysis_pattern, text, flags)\n",
        "\n",
        "    # --- Extract and validate Facts score and explanation ---\n",
        "    facts_explanation = \"\"\n",
        "    facts = None\n",
        "    if facts_match:\n",
        "        facts_explanation = facts_match.group(1).strip()\n",
        "        score_str = facts_match.group(2)\n",
        "        try:\n",
        "            score_int = int(score_str)\n",
        "            # Validate the score is between 1 and 10\n",
        "            if 1 <= score_int <= 10:\n",
        "                facts = score_int\n",
        "            else:\n",
        "                # Score found but outside the valid range\n",
        "                facts = None\n",
        "        except ValueError:\n",
        "            # Should not happen with \\d+ pattern, but handle defensively\n",
        "            facts = None\n",
        "\n",
        "    # --- Extract and validate Cited Articles score and explanation ---\n",
        "    articles_explanation = \"\"\n",
        "    articles = None\n",
        "    if articles_match:\n",
        "        articles_explanation = articles_match.group(1).strip()\n",
        "        score_str = articles_match.group(2)\n",
        "        try:\n",
        "            score_int = int(score_str)\n",
        "            # Validate the score is between 1 and 10\n",
        "            if 1 <= score_int <= 10:\n",
        "                articles = score_int\n",
        "            else:\n",
        "                 # Score found but outside the valid range\n",
        "                articles = None\n",
        "        except ValueError:\n",
        "             # Should not happen with \\d+ pattern, but handle defensively\n",
        "            articles = None\n",
        "\n",
        "    # --- Extract and validate Analysis score and explanation ---\n",
        "    analysis_explanation = \"\"\n",
        "    analysis = None\n",
        "    if analysis_match:\n",
        "        analysis_explanation = analysis_match.group(1).strip()\n",
        "        score_str = analysis_match.group(2)\n",
        "        try:\n",
        "            score_int = int(score_str)\n",
        "            # Validate the score is between 1 and 10\n",
        "            if 1 <= score_int <= 10:\n",
        "                analysis = score_int\n",
        "            else:\n",
        "                 # Score found but outside the valid range\n",
        "                analysis = None\n",
        "        except ValueError:\n",
        "             # Should not happen with \\d+ pattern, but handle defensively\n",
        "            analysis = None\n",
        "\n",
        "    # Return the results in the specified order\n",
        "    return (facts_explanation, articles_explanation, analysis_explanation,\n",
        "            facts, articles, analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XVvRx7cVOJ0k"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "\n",
        "def evaluate_judge_instance(\n",
        "    instance: dict,\n",
        "    candidate_answer: str,\n",
        "    model_id: str,\n",
        "    judge_model: str,\n",
        "    judge_type: str,       # Pass JUDGE_TYPE here (\"spans\" or \"simple\")\n",
        "    system_prompt: str,    # This will be the English system prompt text\n",
        ") -> dict | None:\n",
        "    \"\"\"\n",
        "    Evaluates a single candidate answer against a single dataset instance\n",
        "    using an LLM judge based on the provided English system prompt (1-10 scores),\n",
        "    with a retry mechanism if initial parsing fails for key aspects.\n",
        "\n",
        "    Args:\n",
        "        instance: A dictionary containing data for one evaluation item\n",
        "                  (e.g., {'facts': '...', 'number': '...', 'question': '...',\n",
        "                   'answer': '...', 'chapters': '...', 'spans': {...}}).\n",
        "        candidate_answer: A single string, the candidate answer to evaluate.\n",
        "        model_id: A string identifier for the model that generated this answer.\n",
        "        judge_model: The name of the LLM model to use as the judge.\n",
        "        system_prompt: The system instructions for the judge model (should be the English text expecting 1-10 scores).\n",
        "        judge_type: Indicates the type of judge (\"spans\" or \"simple\").\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with the evaluation result for this answer (with scores 1-10),\n",
        "        or None if critical data is missing (like spans when required).\n",
        "        The dictionary will contain None values for explanations/scores if parsing\n",
        "        failed after all attempts or the LLM call failed.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Extract necessary data from the dataset instance ---\n",
        "    number = instance.get('number', 'N/A') # Use .get for safety\n",
        "    date = instance.get('date', 'N/A') # Use .get for safety\n",
        "    try:\n",
        "        facts = instance.get('facts', '')\n",
        "        question = instance.get('question', '')\n",
        "        gold_answer = instance.get('answer', '')\n",
        "        chapters = instance.get('chapters', '')\n",
        "\n",
        "        spans = instance.get('spans', None)\n",
        "\n",
        "        # Check if spans are required and missing\n",
        "        if judge_type == \"spans\" and spans is None:\n",
        "             print(f\"Error: 'spans' key not found in instance for Question {number} and JUDGE_TYPE is 'spans'. Skipping evaluation for model_id: {model_id}.\")\n",
        "             return None # Return None if spans are critically missing when needed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing dataset instance (Question {number}): {e}. Cannot proceed with evaluation for model_id: {model_id}.\")\n",
        "        return None # Return None for critical data extraction errors\n",
        "\n",
        "    # --- Initialize variables for parsed results (will be updated in the loop) ---\n",
        "    facts_explanation, articles_explanation, analysis_explanation = None, None, None\n",
        "    fact_score, articles_score, analysis_score = None, None, None # Will store 1-10 ints or None\n",
        "\n",
        "    # --- Construct the user prompt for the judge ---\n",
        "    # Ensure field names match what the *English* system prompt expects\n",
        "    spans_str = \"\"\n",
        "    if judge_type == \"spans\" and spans is not None:\n",
        "         # Assuming the system prompt refers to \"Evaluation Spans\"\n",
        "         # Use json.dumps to format the spans dictionary\n",
        "         try:\n",
        "             spans_str = \"\\nEvaluation Spans:\\n\" + json.dumps(spans, indent=2, ensure_ascii=False)\n",
        "         except Exception as e:\n",
        "             print(f\"Warning: Could not JSON dump spans for Question {number}, Model: {model_id}: {e}. Proceeding without spans in prompt.\")\n",
        "             spans_str = \"\" # Ensure it's empty if dumping fails\n",
        "\n",
        "    # If judge_type is 'simple', we don't add the spans JSON.\n",
        "\n",
        "    prompt = (f\"Facts:\\n{facts}\\n\\nRelevant Legislation:\\n{chapters}\\n\\n\"\n",
        "              f\"Question:\\n{question}\\n\\nReference Answer:\\n{gold_answer}\\n\\n\"\n",
        "              f\"Answer for Evaluation:\\n{candidate_answer}\"\n",
        "              f\"{spans_str}\") # Append spans_str only if non-empty and judge_type is spans\n",
        "\n",
        "    # --- Retry Logic ---\n",
        "    max_retries = 1 # 0 means no retries (1 attempt), 1 means 1 retry (2 attempts total)\n",
        "    response = None # Initialize response outside the loop\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        # print(f\"--- Judging Question {number}, Model: {model_id} (Attempt {attempt + 1}/{max_retries + 1}) ---\")\n",
        "\n",
        "        # --- Call the Judge LLM Model ---\n",
        "        # call_gpt should handle potential internal API errors and return None if it cannot get a response\n",
        "        response = call_gpt(judge_model, system_prompt, prompt)\n",
        "\n",
        "        # --- Parse the Judge's Response ---\n",
        "        if response:\n",
        "            (temp_facts_explanation, temp_articles_explanation, temp_analysis_explanation,\n",
        "             temp_fact_score, temp_articles_score, temp_analysis_score) = parse_judgement(response)\n",
        "\n",
        "            # Check if parsing was successful for all *required* elements (explanation and score for each aspect)\n",
        "            # The condition is: NONE of the 6 primary results are None.\n",
        "            all_parsed_ok = all(x is not None for x in [\n",
        "                temp_facts_explanation, temp_articles_explanation, temp_analysis_explanation,\n",
        "                temp_fact_score, temp_articles_score, temp_analysis_score\n",
        "            ])\n",
        "\n",
        "            if all_parsed_ok:\n",
        "                # print(f\"Parsing successful on attempt {attempt + 1}. All fields found.\")\n",
        "                # Assign the successfully parsed temporary results to the main variables\n",
        "                facts_explanation, articles_explanation, analysis_explanation = temp_facts_explanation, temp_articles_explanation, temp_analysis_explanation\n",
        "                fact_score, articles_score, analysis_score = temp_fact_score, temp_articles_score, temp_analysis_score\n",
        "                break # Exit the retry loop as we have a complete result\n",
        "\n",
        "            else:\n",
        "                # Identify which fields are None for logging\n",
        "                missing_fields = []\n",
        "                if temp_facts_explanation is None: missing_fields.append('facts_explanation')\n",
        "                if temp_articles_explanation is None: missing_fields.append('articles_explanation')\n",
        "                if temp_analysis_explanation is None: missing_fields.append('analysis_explanation')\n",
        "                if temp_fact_score is None: missing_fields.append('fact_score')\n",
        "                if temp_articles_score is None: missing_fields.append('articles_score')\n",
        "                if temp_analysis_score is None: missing_fields.append('analysis_score')\n",
        "\n",
        "                print(f\"Parsing failed on attempt {attempt + 1} ({', '.join(missing_fields)} are None).\")\n",
        "                if attempt < max_retries:\n",
        "                    print(\"Retrying judge call...\")\n",
        "                else:\n",
        "                    print(\"Max retries reached. Using the result from the last attempt (may contain None values).\")\n",
        "                    # Even if parsing failed, we keep the results from this last attempt,\n",
        "                    # which might be partially valid, rather than sticking to the initial None.\n",
        "                    # This is important if the second attempt parsed *some* fields correctly.\n",
        "                    # Let's update the main variables with the results from the last attempt,\n",
        "                    # even if partial.\n",
        "                    facts_explanation, articles_explanation, analysis_explanation = temp_facts_explanation, temp_articles_explanation, temp_analysis_explanation\n",
        "                    fact_score, articles_score, analysis_score = temp_fact_score, temp_articles_score, temp_analysis_score\n",
        "                    break # Exit the loop after the last attempt\n",
        "\n",
        "        else:\n",
        "            # LLM call failed (response is None)\n",
        "            print(f\"LLM call failed on attempt {attempt + 1} (response is None).\")\n",
        "            if attempt < max_retries:\n",
        "                print(\"Retrying judge call...\")\n",
        "            else:\n",
        "                print(\"Max retries reached. LLM call failed.\")\n",
        "                # Variables remain None as initialized before the loop\n",
        "                break # Exit the loop after the last attempt\n",
        "\n",
        "    # --- After the loop: Calculate Average Score ---\n",
        "    # Average is (fact_score + articles_score + analysis_score) / 3.0 if all are valid numbers (1-10)\n",
        "    avg = None # Default to None\n",
        "    # Collect scores that are not None and are numeric (integers are fine)\n",
        "    # Use the *final* values of the score variables (fact_score, etc.) which might be None\n",
        "    valid_scores = [score for score in [fact_score, articles_score, analysis_score] if isinstance(score, (int, float)) and score is not None]\n",
        "\n",
        "    if len(valid_scores) == 3: # Only calculate average if all three scores are valid numbers\n",
        "         try:\n",
        "             avg = sum(valid_scores) / 3.0\n",
        "         except Exception as e: # Catch any potential errors during summation/division\n",
        "              print(f\"Error calculating average for Question {number}, Model: {model_id}. Scores: {valid_scores}. Error: {e}. Keeping avg as None.\")\n",
        "              avg = None\n",
        "    elif response is None and all(x is None for x in [facts_explanation, articles_explanation, analysis_explanation, fact_score, articles_score, analysis_score]):\n",
        "         # This check is more specific after the retry loop\n",
        "         print(f\"Warning: LLM call failed after retries or resulted in completely unparseable response for Question {number}, Model: {model_id}. All scores/explanations are None. Result will be stored with None scores.\")\n",
        "         # We still proceed to store the judgement dict with None scores.\n",
        "    elif any(x is None for x in [facts_explanation, articles_explanation, analysis_explanation, fact_score, articles_score, analysis_score]):\n",
        "        # Some fields are None after retries due to partial parsing\n",
        "        score_values = {'facts_exp': facts_explanation, 'articles_exp': articles_explanation, 'analysis_exp': analysis_explanation,\n",
        "                        'facts_score': fact_score, 'articles_score': articles_score, 'analysis_score': analysis_score}\n",
        "        none_fields = {k: v for k, v in score_values.items() if v is None}\n",
        "        print(f\"Warning: Some fields are None after parsing retries for Question {number}, Model: {model_id}. Missing fields: {list(none_fields.keys())}. Average cannot be calculated and is None.\")\n",
        "        # We still proceed to store the judgement dict with partial results and None average.\n",
        "    else:\n",
        "         # This case should only happen if all parsed fields are NOT None, but somehow valid_scores isn't 3 items.\n",
        "         # This indicates a potential logic error in valid_scores or the all_parsed_ok check,\n",
        "         # but print a warning just in case.\n",
        "         print(f\"Warning: Unexpected state - all parsed fields are not None, but could not calculate average for Question {number}, Model: {model_id} ({valid_scores}). Keeping avg as None.\")\n",
        "\n",
        "\n",
        "    # --- Create the result dictionary for this single answer ---\n",
        "    # This dictionary is created regardless of whether scores were successfully parsed or averaged.\n",
        "    # Missing/invalid data will be represented by None values.\n",
        "    judgement = {\n",
        "        'number': number,\n",
        "        'date': date,\n",
        "        'model': model_id,\n",
        "        'judge_model': judge_model,\n",
        "        'judge_type': judge_type,\n",
        "        'facts_explanation': facts_explanation,\n",
        "        'articles_explanation': articles_explanation,\n",
        "        'analysis_explanation': analysis_explanation,\n",
        "        'facts': fact_score,     # Facts Score (1-10 or None)\n",
        "        'articles': articles_score, # Cited Articles Score (1-10 or None)\n",
        "        'analysis': analysis_score, # Analysis Score (1-10 or None)\n",
        "        'avg': avg               # Average (calculated on 1-10 scale or None)\n",
        "    }\n",
        "\n",
        "    return judgement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrtM2W_b9G3k"
      },
      "source": [
        "### Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k0hl2zxF9F24"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "\n",
        "def print_results_table(judgements_list):\n",
        "    \"\"\"\n",
        "    Calculates and prints the average scores for facts, articles, analysis,\n",
        "    and avg from a list of judgement dictionaries, ignoring None values.\n",
        "    Prints the results in a formatted table along with model and judge model.\n",
        "\n",
        "    Args:\n",
        "        judgements_list (list): A list of dictionaries, each representing a judgement.\n",
        "                                 Expected structure: {'model': ..., 'judge_model': ...,\n",
        "                                 'facts': float or None, 'articles': float or None,\n",
        "                                 'analysis': float or None, 'avg': float or None, ...}\n",
        "    \"\"\"\n",
        "    if not judgements_list:\n",
        "        print(\"The list of judgements is empty.\")\n",
        "        return\n",
        "\n",
        "    # Assume model and judge_model are the same for all judgements,\n",
        "    # so we can just take them from the first one.\n",
        "    first_judgement = judgements_list[0]\n",
        "    model = first_judgement.get('model', 'N/A')\n",
        "    judge_model = first_judgement.get('judge_model', 'N/A')\n",
        "\n",
        "    # Collect all non-None scores for each category\n",
        "    facts_scores = [j['facts'] for j in judgements_list if j.get('facts') is not None]\n",
        "    articles_scores = [j['articles'] for j in judgements_list if j.get('articles') is not None]\n",
        "    analysis_scores = [j['analysis'] for j in judgements_list if j.get('analysis') is not None]\n",
        "    avg_scores = [j['avg'] for j in judgements_list if j.get('avg') is not None] # Avg of the calculated avgs\n",
        "\n",
        "    # Calculate averages, handling cases where there are no non-None scores\n",
        "    avg_facts = statistics.mean(facts_scores) if facts_scores else 'N/A'\n",
        "    avg_articles = statistics.mean(articles_scores) if articles_scores else 'N/A'\n",
        "    avg_analysis = statistics.mean(analysis_scores) if analysis_scores else 'N/A'\n",
        "    avg_overall_avg = statistics.mean(avg_scores) if avg_scores else 'N/A'\n",
        "\n",
        "    # Format the output as a table\n",
        "    headers = [\"Model\", \"Judge Model\", \"Facts\", \"Cited Articles\", \"Analysis\", \"Avg\"]\n",
        "    # Define column widths for alignment\n",
        "    col_widths = [25, 25, 12, 14, 14, 18]\n",
        "\n",
        "    # Print header\n",
        "    header_line = \" | \".join(f\"{{:<{w}}}\" for w in col_widths).format(*headers)\n",
        "    print(header_line)\n",
        "    print(\"-|-\".join(\"-\" * w for w in col_widths)) # Separator line\n",
        "\n",
        "    # Format the average values for printing (e.g., 2 decimal places)\n",
        "    # Handle 'N/A' string case\n",
        "    formatted_avg_facts = f\"{avg_facts:.2f}\" if isinstance(avg_facts, (int, float)) else avg_facts\n",
        "    formatted_avg_articles = f\"{avg_articles:.2f}\" if isinstance(avg_articles, (int, float)) else avg_articles\n",
        "    formatted_avg_analysis = f\"{avg_analysis:.2f}\" if isinstance(avg_analysis, (int, float)) else avg_analysis\n",
        "    formatted_avg_overall_avg = f\"{avg_overall_avg:.2f}\" if isinstance(avg_overall_avg, (int, float)) else avg_overall_avg\n",
        "\n",
        "\n",
        "    # Print data row\n",
        "    data_row = [\n",
        "        model,\n",
        "        judge_model,\n",
        "        formatted_avg_facts,\n",
        "        formatted_avg_articles,\n",
        "        formatted_avg_analysis,\n",
        "        formatted_avg_overall_avg\n",
        "    ]\n",
        "    print(\" | \".join(f\"{{:<{w}}}\" for w in col_widths).format(*data_row))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBruXXnx9Jwe"
      },
      "source": [
        "### Evaluate with LLM-Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "hj2abR8vvPXy"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "# import json\n",
        "\n",
        "# judgements = []\n",
        "\n",
        "# for data, answer in tqdm(zip(subset, answers), desc=\"Judging answers\", total=len(subset)):\n",
        "#     # Assuming judge_instance function handles prompt creation and model call internally\n",
        "#     judgement = evaluate_judge_instance(data, answer, MODEL, JUDGE, JUDGE_TYPE, span_judge_system_prompt) # Replace with actual judge function call\n",
        "#     judgements.append(judgement)\n",
        "\n",
        "# output_filename = f\"judgements_{JUDGE}.json\"\n",
        "\n",
        "# try:\n",
        "#     with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "#         json.dump(judgements, f, indent=4, ensure_ascii=False)\n",
        "#     print(f\"\\nSuccessfully saved judgements (JSON) to {output_filename}\")\n",
        "# except IOError as e:\n",
        "#     print(f\"Error saving JSON file {output_filename}: {e}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during JSON serialization: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va-FiTcf9O6r",
        "outputId": "c3010c24-bd63-48f1-e4f7-37248d4687a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded judgements (JSON) from judgements_gpt-4.1-2025-04-14.json\n",
            "{'analysis': 6,\n",
            " 'analysis_explanation': 'Η ανάλυση ακολουθεί σωστή νομική πορεία ως προς την '\n",
            "                         'κύρια βάση της απαίτησης περί απόδοσης του '\n",
            "                         'πράγματος, και αναγνωρίζει την αναγκαιότητα ύπαρξης '\n",
            "                         'σύμβασης και τις ασυμφωνίες επί της ενεργητικής '\n",
            "                         'νομιμοποίησης. Ωστόσο, δεν διακρίνει καθαρά την '\n",
            "                         'επικουρικότητα της αγωγής από αδικαιολόγητο '\n",
            "                         'πλουτισμό (ότι δεν μπορεί να στοιχειοθετηθεί αν '\n",
            "                         'υπάρχει ισχυρή ενοχή και αγωγή ex contractu), κάτι '\n",
            "                         'που είναι βασικό κρίσιμο σημείο του reference. Ως '\n",
            "                         'προς την αποζημίωση, γίνεται αναφορά στην ανάγκη '\n",
            "                         'αιτιώδους συνάφειας και απόδειξης ζημίας, αλλά '\n",
            "                         'λείπει η κριτική στην επάρκεια των αγωγικών '\n",
            "                         'ισχυρισμών ως προς το αίτημα διαφυγόντων κερδών — '\n",
            "                         'αποτυγχάνει να επισημάνει, όπως το reference, ότι το '\n",
            "                         'αίτημα αυτό πιθανόν τυγχάνει αόριστο και χρήζει '\n",
            "                         'απόρριψης λόγω ανεπαρκούς εξειδίκευσης ως προς τα '\n",
            "                         'κρίσιμα περιστατικά και το βάσιμο του κονδυλίου. Το '\n",
            "                         'θέμα της πρόσθετης παρέμβασης τίθεται σωστά, αλλά το '\n",
            "                         'συνολικό αποτέλεσμα δεν καλύπτει πλήρως τη νομική '\n",
            "                         'λογική του reference και αμελεί κρίσιμες πτυχές, '\n",
            "                         'ιδίως ως προς την εγκυρότητα/ορισμένο της προσδοκίας '\n",
            "                         'κέρδους. Το συμπέρασμα ότι η αγωγή “έχει νομική '\n",
            "                         'βάση” είναι ορθό ως προς την απόδοση του πράγματος '\n",
            "                         'και την αποζημίωση κατ’ αρχήν, αλλά δεν μπαίνει στην '\n",
            "                         'κρίσιμη ανάλυση για τη νομική αβασιμότητα της '\n",
            "                         'επικουρικής βάσης και την αοριστία του διαφυγόντος '\n",
            "                         'κέρδους.',\n",
            " 'articles': 6,\n",
            " 'articles_explanation': 'Η απάντηση επικαλείται ορθά τα άρθρα 810 ΑΚ '\n",
            "                         '(χρησιδάνειο και επιστροφή πράγματος - πολύ '\n",
            "                         'σημαντικό), άρθρα 298, 330 και 343 ΑΚ για '\n",
            "                         'αποζημίωση, δηλαδή τόσο για τη θετική ζημία όσο και '\n",
            "                         'για διαφυγόν κέρδος. Ωστόσο, η αναφορά σε 330 και '\n",
            "                         '343 ΑΚ δεν συνοδεύεται από επεξηγήσεις για τις '\n",
            "                         'προϋποθέσεις υπερημερίας (340, 341, 343 ΑΚ με την '\n",
            "                         'έννοια της δήλης μέρας/ληξιπροθέσμιας απαίτησης και '\n",
            "                         'της απαίτησης όχλησης που είναι σημαντική και '\n",
            "                         'αναπτύσσεται στο reference). Δεν αναφέρει το άρθρο '\n",
            "                         '904 ΑΚ (αδικαιολόγητος πλουτισμός) και τις '\n",
            "                         'προϋποθέσεις επικουρικότητας, ούτε τα άρθρα 1094 επ. '\n",
            "                         'ΑΚ για τη δυνατότητα διεκδικητικής αγωγής, ούτε το '\n",
            "                         '216 ΚΠολΔ για το ορισμένο του αιτήματος (σημαντικό '\n",
            "                         'για το διαφυγόν κέρδος). Γίνεται αναφορά στο άρθρο '\n",
            "                         '80 ΚΠολΔ για την πρόσθετη παρέμβαση, που είναι '\n",
            "                         'σωστή. Εν κατακλείδι, γίνεται ρητή παράθεση βασικών '\n",
            "                         'άρθρων της ουσίας και της διαδικασίας, αλλά όχι με '\n",
            "                         'το εύρος και την ανάλυση που ζητείται στο πρότυπο. '\n",
            "                         'Δεν γίνεται λάθος ερμηνεία, αλλά οι ελλείψεις είναι '\n",
            "                         'ουσιώδεις.',\n",
            " 'avg': 6.333333333333333,\n",
            " 'date': 'A_2023',\n",
            " 'facts': 7,\n",
            " 'facts_explanation': 'Η απάντηση για αξιολόγηση αναφέρει τα βασικά πραγματικά '\n",
            "                      'δεδομένα της υπόθεσης: το αίτημα απόδοσης του γεωργικού '\n",
            "                      'μηχανήματος λόγω λήξης της σύμβασης χρησιδανείου '\n",
            "                      '(αναφέρεται η ημερομηνία λήξης), τη διεκδικούμενη '\n",
            "                      'αποζημίωση για θετική ζημία (δαπάνη μίσθωσης άλλου '\n",
            "                      'μηχανήματος) και διαφυγόν κέρδος, και την ένσταση '\n",
            "                      'ενεργητικής νομιμοποίησης της εναγομένης, καθώς και την '\n",
            "                      'πρόσθετη παρέμβαση του Δ λόγω της σύμβασης πώλησης. '\n",
            "                      'Ωστόσο, απουσιάζει η λεπτομερής αναφορά στους κρίσιμους '\n",
            "                      'όρους της σύμβασης χρησιδανείου (λήξη χορήγησης, '\n",
            "                      'συμφωνία φιλικής παραχωρήσεως), η επισήμανση ότι η βάση '\n",
            "                      'του αδικαιολόγητου πλουτισμού είναι επικουρική, και η '\n",
            "                      'επισήμανση ως προς την αοριστία του αιτήματος '\n",
            "                      'διαφυγόντων κερδών λόγω μη επαρκούς εξειδίκευσης. '\n",
            "                      'Επισημαίνει μεν στοιχεία της ζημίας (μίσθωση/διαφυγόν '\n",
            "                      'κέρδος), αλλά δεν σχολιάζει αν αυτά τα στοιχεία αρκούν '\n",
            "                      'προς το ορισμένο της αγωγής (όπως θέτει το reference). '\n",
            "                      'Τέλος, δεν γίνεται περαιτέρω διάκριση μεταξύ των επί '\n",
            "                      'μέρους αιτημάτων του Α. Γενικά, τα βασικά πραγματικά '\n",
            "                      'ζητήματα τίθενται αλλά λείπουν κρίσιμες αναφορές.',\n",
            " 'judge_model': 'gpt-4.1-2025-04-14',\n",
            " 'judge_type': 'span',\n",
            " 'model': 'gemini-2.0-flash-001',\n",
            " 'number': 1}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "input_filename = f\"judgements_{JUDGE}.json\"\n",
        "\n",
        "loaded_judgements_from_json = []\n",
        "\n",
        "try:\n",
        "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
        "        loaded_judgements_from_json = json.load(f)\n",
        "\n",
        "    if isinstance(loaded_judgements_from_json, list) and all(isinstance(item, dict) for item in loaded_judgements_from_json):\n",
        "        print(f\"Successfully loaded judgements (JSON) from {input_filename}\")\n",
        "    else:\n",
        "        print(f\"Warning: Data loaded from {input_filename} is not a list of dicts as expected.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {input_filename} was not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from {input_filename}. The file might be corrupted or not valid JSON.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error reading file {input_filename}: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "pprint(loaded_judgements_from_json[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT2HADLv8Z9u",
        "outputId": "c64e3622-89d5-4e22-d729-c0ec7bc32695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model                     | Judge Model               | Facts        | Cited Articles | Analysis       | Avg               \n",
            "--------------------------|---------------------------|--------------|----------------|----------------|-------------------\n",
            "gemini-2.0-flash-001      | gpt-4.1-2025-04-14        | 8.30         | 7.37           | 7.33           | 7.67              \n"
          ]
        }
      ],
      "source": [
        "print_results_table(loaded_judgements_from_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "785_Y9cvLraY"
      },
      "source": [
        "# Meta-evaluate judge-model on **GBB-JME**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDXBBsoDqBnH"
      },
      "source": [
        "## Generate judgements with an LLM-judge on GBB-JME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKvaa0F6vXvp"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474,
          "referenced_widgets": [
            "749214343d2b49b8b32b379cab78f8fe",
            "a2bfaa7299b4482e84bf2720f9e38f6a",
            "39bf0e5a3bd74096a375cd0defb0d601",
            "c159bfa746fb44069dcee6579d6be8a4",
            "42a7d26b256f4e63b338ff007912186a",
            "73d5735fe6974703a7af9af6f100412d",
            "61df6e4502ea4536b59346ecf3706bb9",
            "acd8e2671e9e4029927f66fa7acd04dc",
            "8a1f21e3a1374441865cfa700b3978c9",
            "53fad2f0b31446878a36847a7267aec9",
            "771be62d864649d0ba3a57b838c2f7cf"
          ]
        },
        "id": "-daiAL1jLwG4",
        "outputId": "b06d4b75-8c67-43a4-d1c5-990d41f0dcd1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "749214343d2b49b8b32b379cab78f8fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/305 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "{'analysis': 9.0,\n",
            " 'area': 'criminal',\n",
            " 'articles': 9.0,\n",
            " 'avg': 9.0,\n",
            " 'date': 'A_2023',\n",
            " 'facts': 9.0,\n",
            " 'index': 160,\n",
            " 'model': 'gemini-2.0-flash-001',\n",
            " 'number': 1,\n",
            " 'reasoning': None,\n",
            " 'response': 'Η ποινική αξιολόγηση της συμπεριφοράς των Α και Β έχει ως εξής: '\n",
            "             'Ο Β, εισερχόμενος στην οικία της Π με σκοπό την αφαίρεση '\n",
            "             \"χρημάτων και τιμαλφών (προτάσεις 1, 3), διαπράττει κλοπή κατ' \"\n",
            "             \"άρθρο 372 ΠΚ. Η πράξη του μετατρέπεται σε ληστεία κατ' άρθρο 380 \"\n",
            "             'παρ. 1 ΠΚ, καθώς ασκεί σωματική βία εναντίον της Π για να '\n",
            "             'αφαιρέσει τα χρήματα και τα τιμαλφή (προτάσεις 5, 7). Επιπλέον, '\n",
            "             'η πράξη τελέστηκε με καλυμμένα ή αλλοιωμένα χαρακτηριστικά, '\n",
            "             'γεγονός που συνιστά επιβαρυντική περίσταση. Ο Α, ενεργώντας με '\n",
            "             'δόλο, προκαλεί τον Β να διαπράξει τη ληστεία (προτάσεις 1, 2), '\n",
            "             'συνεπώς είναι ηθικός αυτουργός κατά το άρθρο 46 παρ. 1α ΠΚ, και '\n",
            "             'τιμωρείται με την ποινή του αυτουργού. Τέλος, η ομολογία των Α '\n",
            "             'και Β στην αστυνομική προανάκριση (πρόταση 8) δεν επηρεάζει το '\n",
            "             'αξιόποινο των πράξεών τους, αλλά μπορεί να ληφθεί υπόψη ως '\n",
            "             'ελαφρυντική περίσταση κατά την επιμέτρηση της ποινής.\\n'}\n"
          ]
        }
      ],
      "source": [
        "subset_jme = dataset_jme.filter(\n",
        "    lambda example: example['date'] == 'A_2023' and example['area'] == 'criminal'\n",
        ")\n",
        "print(len(subset_jme))\n",
        "pprint(subset_jme[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nS1LqBevZFi"
      },
      "source": [
        "### GBB-JME judgements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "le1JRx5JvaWj"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "# import json\n",
        "\n",
        "# jme_judgements = []\n",
        "\n",
        "# for jme_data in tqdm(subset_jme, desc=f\"Judging GBB-JME answers using the {JUDGE} judge\"):\n",
        "#     index = jme_data.get('index', 'N/A')\n",
        "#     model = jme_data.get('model', 'N/A')\n",
        "#     answer = jme_data.get('response', 'N/A')\n",
        "#     data = dataset[index]\n",
        "#     judgement = evaluate_judge_instance(data, answer, model, JUDGE, JUDGE_TYPE, span_judge_system_prompt)\n",
        "#     jme_judgements.append(judgement)\n",
        "\n",
        "# output_filename = f\"jme_judgements_{JUDGE}.json\"\n",
        "\n",
        "# try:\n",
        "#     with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "#         json.dump(jme_judgements, f, indent=4, ensure_ascii=False)\n",
        "#     print(f\"\\nSuccessfully saved jme_judgements (JSON) to {output_filename}\")\n",
        "# except IOError as e:\n",
        "#     print(f\"Error saving JSON file {output_filename}: {e}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during JSON serialization: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt3Gfh0P5atx",
        "outputId": "caf5cc8a-40df-4b5a-da90-f689abc64a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded judgements (JSON) from jme_judgements_gpt-4.1-2025-04-14.json\n",
            "{'analysis': 7,\n",
            " 'analysis_explanation': 'Η απάντηση τελειώνει σωστά με το συμπέρασμα ότι ο Β '\n",
            "                         'είναι αυτουργός ληστείας και ο Α ηθικός αυτουργός '\n",
            "                         'στη ληστεία, συνδέοντας επαρκώς τα πραγματικά '\n",
            "                         'περιστατικά με τη νομική κατάταξη και τους σχετικούς '\n",
            "                         'ρόλους (αυτουργός-ηθικός αυτουργός). Η ανάλυση είναι '\n",
            "                         'ωστόσο λιγότερο λεπτομερής από το ιδανικό ως προς τη '\n",
            "                         'δομή και δεν επεξηγεί πλήρως, αφενός, το ζήτημα της '\n",
            "                         'βαρύτερης πράξης (αν ο Α θα ήταν ηθικός αυτουργός '\n",
            "                         'μόνο για κλοπή ή και για ληστεία – δεν εξηγεί το '\n",
            "                         'σκεπτικό του ενδεχόμενου δόλου), αφετέρου, δεν '\n",
            "                         'αναφέρει το κλασικό όριο της \"ειδικότητα προτροπής\" '\n",
            "                         '(ότι αρκεί και ενδεχόμενος δόλος στην ηθική '\n",
            "                         'αυτουργία για να στοιχειοθετηθεί ηθική αυτουργία για '\n",
            "                         'το βαρύτερο έγκλημα της ληστείας και όχι μόνο για '\n",
            "                         'την κλοπή). Επιπλέον, καταγράφεται αστοχία για '\n",
            "                         '«κάλυψη ή αλλοίωση χαρακτηριστικών», που δεν '\n",
            "                         'προκύπτει από τα πραγματικά περιστατικά και θα '\n",
            "                         'μπορούσε να οδηγήσει σε εσφαλμένη ποινική αξιολόγηση '\n",
            "                         '(αν π.χ. είχαμε ανάλυση ποινής για επιβαρυντική '\n",
            "                         'περίπτωση), αν και δεν αλλάζει το ζητούμενο '\n",
            "                         'συμπέρασμα της υπόστασης. Επίσης, η τελευταία '\n",
            "                         'πρόταση περί ομολογίας και ελαφρυντικής περίστασης '\n",
            "                         'είναι σωστή μόνο ως πρακτική δικονομική επισήμανση '\n",
            "                         'και δεν επηρεάζει τη νομολογιακή δομή.',\n",
            " 'articles': 8,\n",
            " 'articles_explanation': 'Ο εξεταζόμενος σωστά αναφέρεται στα άρθρα 372 '\n",
            "                         '(κλοπή), 380 παρ. 1 ΠΚ (ληστεία) για την πράξη του Β '\n",
            "                         'και στο άρθρο 46 παρ. 1α για την ηθική αυτουργία του '\n",
            "                         'Α. Έχει διαγραφεί στο κείμενο η σύνδεση με το άρθρο '\n",
            "                         '27 παρ. 1 (ενδεχόμενος δόλος), που υπήρχε στο '\n",
            "                         'ιδανικό, και αυτό είναι μειονέκτημα, καθώς η '\n",
            "                         'εξειδίκευση/ερμηνεία του ποινικού δόλου σε αυτή την '\n",
            "                         'περίπτωση έχει σημασία για να κριθεί ο Α ως ηθικός '\n",
            "                         'αυτουργός ληστείας και όχι μόνο κλοπής. Αναφέρει το '\n",
            "                         'άρθρο 372 ΠΚ, το οποίο εν προκειμένω εκπληρώνει ρόλο '\n",
            "                         'μόνο περιγραφικό (πρωταρχική περιγραφή πράξης, πριν '\n",
            "                         'αναχθεί σε ληστεία), ενώ βασικό είναι η πληρότητα '\n",
            "                         'στην επίκληση όλων των κρίσιμων άρθρων. Τα άρθρα '\n",
            "                         'πάντως που αναφέρονται, είναι τα απολύτως κομβικά.\\n'\n",
            "                         'Υπάρχει όμως και λάθος: γίνεται αναφορά σε '\n",
            "                         '«επιβαρυντική περίπτωση» λόγω καλυμμένων '\n",
            "                         'χαρακτηριστικών, που δεν ισχύει βάσει των '\n",
            "                         'πραγματικών περιστατικών – αυτό είναι '\n",
            "                         'νομικό/ερμηνευτικό σφάλμα. Τέλος, η διατύπωση '\n",
            "                         '\"τιμωρείται με την ποινή του αυτουργού\" είναι ορθή, '\n",
            "                         'αλλά δεν αναλύει επακριβώς την εσωτερική νομική βάση '\n",
            "                         'όπως το ιδανικό, δηλαδή την προϋπόθεση '\n",
            "                         'πρόθεσης-ενδεχόμενου δόλου και ότι αυτό επαρκεί για '\n",
            "                         'το άρθρο 46 παρ.1 σε συνδυασμό με 380 ΠΚ.',\n",
            " 'avg': 7.666666666666667,\n",
            " 'date': 'A_2023',\n",
            " 'facts': 8,\n",
            " 'facts_explanation': 'Η αξιολογούμενη απάντηση περιλαμβάνει τα βασικά και '\n",
            "                      'κρίσιμα πραγματικά περιστατικά: περιγράφει ότι ο Β '\n",
            "                      'εισήλθε στην οικία με σκοπό την αφαίρεση χρημάτων και '\n",
            "                      'τιμαλφών, αυτά ανήκαν στην Π, ασκήθηκε σωματική βία '\n",
            "                      'εναντίον της Π, τα χρήματα αφαιρέθηκαν, και η πράξη '\n",
            "                      'χαρακτηρίζεται ως ληστεία. Αναφέρει ακόμα τον ρόλο του '\n",
            "                      'Α ως εκείνου που ώθησε τον Β σε αυτή την πράξη '\n",
            "                      '(πειθώ-φόρτιση-συνεχείς προτροπές), αν και συνοπτικά. '\n",
            "                      'Επίσης γίνεται αναφορά στην ομολογία αμφοτέρων μετά από '\n",
            "                      'ένα μήνα στην αστυνομική προανάκριση, αν και αυτό δεν '\n",
            "                      'αποτελεί κρίσιμο πραγματικό στοιχείο για τη θεμελίωση '\n",
            "                      'της αντικειμενικής ή υποκειμενικής υπόστασης του '\n",
            "                      'αδικήματος (πιο πολύ έχει σημασία για δικονομικά ή για '\n",
            "                      'ελαφρυντικά). Ωστόσο, από την αξιολόγηση των critical '\n",
            "                      'και non-critical spans του ιδανικού, η απάντηση δεν '\n",
            "                      'εξηγεί όσο αναλυτικά και με σαφή αναφορά στην έννοια '\n",
            "                      'του ενδεχόμενου δόλου για τον Α (ότι δηλαδή αποδεχόταν '\n",
            "                      'και την περίπτωση να χρησιμοποιηθεί βία αν συναντηθεί η '\n",
            "                      'Π εντός οικίας)∙ περιορίζεται σε λιγότερο λεπτομερή '\n",
            "                      'ανάλυση ως προς το γεγονός ότι η προτροπή του Α δεν '\n",
            "                      'αφορούσε μόνο κλοπή, αλλά ότι αποδεχόταν και το '\n",
            "                      'ενδεχόμενο βίας. Παράλληλα, ο αξιολογούμενος '\n",
            "                      'υποστηρίζει ότι τελέστηκε η πράξη με καλυμμένα ή '\n",
            "                      'αλλοιωμένα χαρακτηριστικά προσώπου, κάτι που δεν '\n",
            "                      'προκύπτει από τα πραγματικά περιστατικά και είναι '\n",
            "                      'λανθασμένη προσθήκη/διαπίστωση. Ως εκ τούτου, η κάλυψη '\n",
            "                      'των γεγονότων είναι γενικά καλή αλλά όχι πλήρως '\n",
            "                      'αναλυτική ή απόλυτα ακριβής.',\n",
            " 'judge_model': 'gpt-4.1-2025-04-14',\n",
            " 'judge_type': 'span',\n",
            " 'model': 'gemini-2.0-flash-001',\n",
            " 'number': 1}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "input_filename = f\"jme_judgements_{JUDGE}.json\"\n",
        "\n",
        "jme_judgements = []\n",
        "\n",
        "try:\n",
        "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
        "        jme_judgements = json.load(f)\n",
        "\n",
        "    if isinstance(jme_judgements, list) and all(isinstance(item, dict) for item in jme_judgements):\n",
        "        print(f\"Successfully loaded judgements (JSON) from {input_filename}\")\n",
        "    else:\n",
        "        print(f\"Warning: Data loaded from {input_filename} is not a list of dicts as expected.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {input_filename} was not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from {input_filename}. The file might be corrupted or not valid JSON.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error reading file {input_filename}: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "pprint(jme_judgements[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymTWzQKobKyr"
      },
      "source": [
        "## Meta-evaluation of the LLM-judge on GBB-JME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL7gV2rzhSfa"
      },
      "source": [
        "#### SPA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Aq0gC29nbPFv"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Brian Thompson. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_pairwise_p_values(seg_scores, num_permutations=1000, seed: int = 4):\n",
        "    \"\"\"\n",
        "    Author: Brian Thompson\n",
        "    Date: June 2024\n",
        "\n",
        "    Suppose we have test set consisting of L=5 segments, and two systems, systemsA and systemB,\n",
        "    for which we have segment-level scores scoresA and scoresB:\n",
        "       scoresA = [0.8, 0.9, 0.7, 1.0, 0.6]\n",
        "       scoresB = [0.2, 0.3, 0.1, 0.4, 0.0]\n",
        "\n",
        "    Typically we would average segment-level scores to get system level scores, but for convenience later on\n",
        "    we will define system scores to be the sum of segment-level scores. This gives us a delta system-level score of:\n",
        "        test_delta = sum(scoresA) - sum(scoresB) = 4.0 - 1.0 = 3.0\n",
        "\n",
        "    To run a paired permutation test, we first generate a new set of scores scores0,\n",
        "    where each score0[i] is randomly selected from either scoresA[i] or scoresB[i].\n",
        "    Let's define a random boolean mask:\n",
        "       m = [1, 0, 0, 1, 1]\n",
        "\n",
        "    and used it to select scores0:\n",
        "       scores0 = m.*scoresA + (1-m).*scoresB = [0.8, 0.3, 0.1, 1.0, 0.6]   # selected from [A, B, B, A, A], respectively\n",
        "\n",
        "    Likewise, we compose scores1 using all the scores which were not selected for scores0:\n",
        "       scores1 = (1-m).*scoresA + m.*scoresB = [0.2, 0.9, 0.7, 0.4, 0.0]   # selected from [B, A, A, B, B], respectively\n",
        "\n",
        "    To get the delta system-level score for our two mock systems, we need to compute:\n",
        "       null_delta = sum(scores0) - sum(scores1)\n",
        "                  = sum(m.*scoresA + (1-m).*scoresB) - sum((1-m).*scoresA + m.*scoresB)\n",
        "                  = sum((2m-1).*scoresA) - sum((2m-1).*scoresB\n",
        "                  = (2m-1) * scoresA.T - (2m-1) * scoresB.T\n",
        "                  = [ 1, -1, -1,  1,  1] * [[0.8],  -  [ 1, -1, -1,  1,  1] * [[0.2],  =  0.8 - 0.2  =  0.6\n",
        "                                            [0.9],                             [0.3],\n",
        "                                            [0.7],                             [0.1],\n",
        "                                            [1.0],                             [0.4],\n",
        "                                            [0.6]]                             [0.0]]\n",
        "\n",
        "    To compute many different permutations, we replace the vector m with a matrix of size (num_permutations, L):\n",
        "       null_delta = [[ 1,  1, -1, -1, -1], * [[0.8],  -  [[ 1,  1, -1, -1, -1], * [[0.2],  = [[-0.6],  - [[ 0.0],   =  [[-0.6]\n",
        "                     [ 1, -1,  1, -1,  1],    [0.9],      [ 1, -1,  1, -1,  1],    [0.3],     [ 0.2],     [-0.4],       [ 0.6],\n",
        "                     [ 1, -1,  1,  1, -1],    [0.7],      [ 1, -1,  1,  1, -1],    [0.1],     [ 1.0],     [ 0.4],       [ 0.6],\n",
        "                     [-1,  1, -1, -1,  1],    [1.0],      [-1,  1, -1, -1,  1],    [0.4],     [-1.0],     [-0.4],       [-0.6],\n",
        "                     [ 1,  1,  1, -1,  1],    [0.6]]      [ 1,  1,  1, -1,  1],    [0.0]]     [ 2.0],     [ 0.2],       [ 1.8],\n",
        "                     [-1,  1, -1,  1, -1],                [-1,  1, -1,  1, -1],               [-0.2],     [ 0.4],       [-0.6],\n",
        "                     [ 1,  1,  1,  1,  1],                [ 1,  1,  1,  1,  1],               [ 4.0],     [ 1.0],       [ 3.0],\n",
        "                     [ 1, -1,  1, -1,  1],                [ 1, -1,  1, -1,  1],               [ 0.2],     [-0.4],       [ 0.6],\n",
        "                     [ 1,  1, -1, -1,  1],                [ 1,  1, -1, -1,  1],               [ 0.6],     [ 0.0],       [ 0.6],\n",
        "                     [-1,  1, -1, -1, -1]]                [ 1, -1, -1,  1, -1]]               [-2.2]]     [-0.4]]       [-1.8]]\n",
        "\n",
        "    To test the significance that system A is better than system B, we compute:\n",
        "       null_delta >= test_delta  =  [[-0.6]  >= 3   =   [[False],\n",
        "                                     [ 0.6],             [False],\n",
        "                                     [ 0.6],             [False],\n",
        "                                     [-0.6],             [False],\n",
        "                                     [ 1.8],             [False],\n",
        "                                     [-0.6],             [False],\n",
        "                                     [ 3.0],             [True ],\n",
        "                                     [ 0.6],             [False],\n",
        "                                     [ 0.6],             [False],\n",
        "                                     [-1.8]]             [False]]\n",
        "\n",
        "    The p value is the fraction of the time that null_delta >= test_delta, in this case 1/10 = 0.1\n",
        "\n",
        "    The above discussion was for a single system pair, but we actually need to compute p values for each pairwise\n",
        "    within a set systems systemA, systemB, ... systemN. In practice, the computation bottleneck is generating\n",
        "    the random boolean vector m, so we generate m once and use it for all pairs of systems.\n",
        "\n",
        "    Reusing m also allows us to avoid most of the N^2 computations by pre-computing (2m-1) * scoresA.T,\n",
        "    (2m-1) * scoresB.T, ..., (2m-1) * scoresN.T.\n",
        "\n",
        "    Test speed:\n",
        "    python -m timeit -s \"import numpy as np; from pairwise_paired_permutation_test import compute_pairwise_p_values; x=np.random.random(size=(14,1300))\" \"compute_pairwise_p_values(x, num_permutations=1000)\"\n",
        "\n",
        "    :param seg_scores: segment-level scores, with shape (num_systems, num_segments)\n",
        "    :param num_permutations: Number of permutations for permutation test\n",
        "    :param seed: The random seed\n",
        "    :return: np.array of size (num_systems, num_systems), where the upper triangle has been populated\n",
        "       with p-values for the hypothesis that system[i] > system[j]\n",
        "    \"\"\"\n",
        "    num_systems, num_segments = seg_scores.shape\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    # initialize in range [0, 1)\n",
        "    two_m_minus_one = rng.random(size=(num_permutations, num_segments), dtype=np.float32)\n",
        "    # quantize to 0 or 1, in place\n",
        "    np.rint(two_m_minus_one, out=two_m_minus_one, casting='same_kind')\n",
        "    # scale and shift to get -1.0 and +1.0, in place\n",
        "    two_m_minus_one *= 2.0\n",
        "    two_m_minus_one -= 1.0\n",
        "\n",
        "    seg_scores = seg_scores.astype(np.float32)  # shape: (num_systems, num_segments)\n",
        "    sys_scores = np.sum(seg_scores, axis=1)  # shape: (num_systems, )\n",
        "\n",
        "    partial = np.matmul(two_m_minus_one, seg_scores.T)  # shape: (num_permutations, num_systems)\n",
        "\n",
        "    # initialize p value matrix to NaN\n",
        "    p_vals = np.empty((num_systems, num_systems,)) * np.nan\n",
        "    # populate upper triangle\n",
        "    for ii in range(num_systems):\n",
        "        for jj in range(ii + 1, num_systems):\n",
        "            null_delta = partial[:, ii] - partial[:, jj]  # shape: (num_permutations, )\n",
        "            test_delta = sys_scores[ii] - sys_scores[jj]  # float\n",
        "            p_vals[ii, jj] = np.sum(null_delta >= test_delta) / num_permutations\n",
        "\n",
        "    return p_vals\n",
        "\n",
        "\n",
        "def compute_one_minus_pce(human_pairwise_p_vals, metric_pairwise_p_vals):\n",
        "    \"\"\"\n",
        "    Author: Brian Thompson\n",
        "    Date: June 2024\n",
        "\n",
        "    Pairwise Confidence Error (PCE) is the absolute difference between\n",
        "      the p value for the conclusion that one system is better than another given human judgements and\n",
        "      the p value for the conclusion for the same system comparison given metric judgements,\n",
        "      averaged over all system pairings for a set of systems.\n",
        "\n",
        "    We return 1-PCE to be comparable with pairwise accuracy [i.e. range from 0 to 1, higher is better]\n",
        "\n",
        "    :param human_pairwise_p_vals: np.array of shape (num_systems, num_systems),\n",
        "        where the upper triangle has been populated with p-values for system[i] > system[j]\n",
        "        computed from human judgements\n",
        "    :param metric_pairwise_p_vals: np.array of shape (num_systems, num_systems),\n",
        "        where the opper triangle has been populated with p-values for system[i] > system[j]\n",
        "        computed from metric scores\n",
        "    :return: 1-PCE\n",
        "    \"\"\"\n",
        "    num_systems = human_pairwise_p_vals.shape[0]\n",
        "    upper_tri_idxs = np.triu_indices(num_systems, 1)\n",
        "    return 1.0 - np.mean(np.abs(human_pairwise_p_vals - metric_pairwise_p_vals)[upper_tri_idxs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fbmTeFsthU16"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"PairwiseConfidenceError or Soft Pairwise Accuracy (SPA)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing\n",
        "\n",
        "\n",
        "\n",
        "ArrayLike = numpy.typing.ArrayLike\n",
        "\n",
        "\n",
        "def PairwiseConfidenceError(\n",
        "    gold_scores: list[ArrayLike],\n",
        "    metric_scores: list[ArrayLike],\n",
        "    num_sys: int,\n",
        "    num_permutations: int = 1000,\n",
        ") -> tuple[float, ...]:\n",
        "  \"\"\"Calculates pairwise confidence error (PCE).\"\"\"\n",
        "\n",
        "  # Convert the gold and metric scores into N x M matrices where N is the\n",
        "  # number of systems and M is the number of segments.\n",
        "  gold = _Reshape(gold_scores, num_sys, 'sys')\n",
        "  metric = _Reshape(metric_scores, num_sys, 'sys')\n",
        "\n",
        "  gold_pvalues = compute_pairwise_p_values(\n",
        "      gold, num_permutations=num_permutations\n",
        "  )\n",
        "  metric_pvalues = compute_pairwise_p_values(\n",
        "      metric, num_permutations=num_permutations\n",
        "  )\n",
        "  return (compute_one_minus_pce(gold_pvalues, metric_pvalues),)\n",
        "\n",
        "\n",
        "def _Reshape(vector, num_sys, average_by):\n",
        "  \"\"\"Reshape a packed vector into a matrix for row averaging.\"\"\"\n",
        "  if average_by == 'none':\n",
        "    return np.asarray(vector).reshape(1, -1)\n",
        "  elif average_by == 'sys':\n",
        "    return np.asarray(vector).reshape(num_sys, -1)\n",
        "  elif average_by == 'item':\n",
        "    return np.asarray(vector).reshape(num_sys, -1).transpose()\n",
        "  else:\n",
        "    raise ValueError(f'Unknown averaging option: {average_by}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "T4vE8yNvhYnE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def gather_scores_for_pce(systems, judgements):\n",
        "    \"\"\"\n",
        "    Gathers scores from a list of judgements for given systems and structures them\n",
        "    for PCE calculation. Returns four lists:\n",
        "    1. total_flat: [s1q1f, s1q1r, s1q1a, s2q1f, ...] (length N_s * N_q * 3)\n",
        "    2. facts_pce:  [s1q1f, s2q1f, ..., snq1f, s1q2f, ...] (length N_s * N_q)\n",
        "    3. articles_pce:  [s1q1r, s2q1r, ..., snq1r, s1q2r, ...] (length N_s * N_q)\n",
        "    4. analysis_pce: [s1q1a, s2q1a, ..., snq1a, s1q2a, ...] (length N_s * N_q)\n",
        "\n",
        "    Where sX is system X, qY is question Y, f/r/a are facts/articles/analysis scores,\n",
        "    N_s is number of systems, N_q is number of questions.\n",
        "    Scores are ordered by question (ascending 'number'), then by system (as provided in 'systems' list)\n",
        "    within the metric-specific lists (facts_pce, articles_pce, analysis_pce).\n",
        "    Scores for total_flat are ordered by question, then by system, then by metric (facts, articles, analysis).\n",
        "    Assumes each judgement dict contains 'number', 'model', 'facts', 'articles', 'analysis'.\n",
        "    Handles missing judgements for a system/question by using None.\n",
        "    \"\"\"\n",
        "    total_flat = []\n",
        "    facts_pce = []\n",
        "    articles_pce = []\n",
        "    analysis_pce = []\n",
        "\n",
        "    if not judgements: # Check if the input list is empty\n",
        "        print(\"Warning: Input judgements list is empty.\")\n",
        "        return [], [], [], []\n",
        "\n",
        "    # Structure data by question number and then by system name\n",
        "    # { q_id: { sys_name: { 'facts': score, 'articles': score, 'analysis': score } } }\n",
        "    data_by_question = {}\n",
        "    all_q_ids_set = set() # Use a set to collect unique question IDs efficiently\n",
        "\n",
        "    for judgement in judgements:\n",
        "        q_id = judgement.get('number')\n",
        "        sys = judgement.get('model')\n",
        "        f_score = judgement.get('facts')\n",
        "        r_score = judgement.get('articles')\n",
        "        a_score = judgement.get('analysis')\n",
        "\n",
        "        # Ensure we have necessary keys\n",
        "        if q_id is None or sys is None:\n",
        "             # print(f\"Warning: Skipping judgement with missing 'number' or 'model': {judgement}\")\n",
        "             continue # Skip entries without essential info\n",
        "\n",
        "        all_q_ids_set.add(q_id)\n",
        "\n",
        "        if q_id not in data_by_question:\n",
        "            data_by_question[q_id] = {}\n",
        "        if sys not in data_by_question[q_id]:\n",
        "             data_by_question[q_id][sys] = {}\n",
        "\n",
        "        # Store scores, converting to float and handling None or potential non-numeric types\n",
        "        try:\n",
        "            data_by_question[q_id][sys]['facts'] = float(f_score) if f_score is not None else None\n",
        "        except (ValueError, TypeError):\n",
        "            print(f\"Warning: Could not convert facts score '{f_score}' to float for number {q_id}, model {sys}. Using None.\")\n",
        "            data_by_question[q_id][sys]['facts'] = None\n",
        "\n",
        "        try:\n",
        "            data_by_question[q_id][sys]['articles'] = float(r_score) if r_score is not None else None\n",
        "        except (ValueError, TypeError):\n",
        "             print(f\"Warning: Could not convert articles score '{r_score}' to float for number {q_id}, model {sys}. Using None.\")\n",
        "             data_by_question[q_id][sys]['articles'] = None\n",
        "\n",
        "        try:\n",
        "            data_by_question[q_id][sys]['analysis'] = float(a_score) if a_score is not None else None\n",
        "        except (ValueError, TypeError):\n",
        "             print(f\"Warning: Could not convert analysis score '{a_score}' to float for number {q_id}, model {sys}. Using None.\")\n",
        "             data_by_question[q_id][sys]['analysis'] = None\n",
        "\n",
        "\n",
        "    # Get sorted unique question IDs for consistent ordering\n",
        "    all_q_ids = sorted(list(all_q_ids_set))\n",
        "\n",
        "    # Now flatten the scores into the required list structures\n",
        "    # Ensure ordering by q_id then sys according to the 'systems' list\n",
        "    for q_id in all_q_ids:\n",
        "        for sys in systems: # Iterate through the *expected* systems list\n",
        "            # Retrieve scores for this q_id and sys. Use .get() with default\n",
        "            # to handle cases where a system from the input 'systems' list\n",
        "            # doesn't appear in the judgements for this specific question.\n",
        "            scores = data_by_question.get(q_id, {}).get(sys, {'facts': None, 'articles': None, 'analysis': None})\n",
        "\n",
        "            f_score = scores['facts']\n",
        "            r_score = scores['articles']\n",
        "            a_score = scores['analysis']\n",
        "\n",
        "            # total_flat structure: [s1q1f, s1q1r, s1q1a, s2q1f, s2q1r, s2q1a, ...]\n",
        "            # Append scores for the current system/question combination\n",
        "            total_flat.extend([f_score, r_score, a_score])\n",
        "\n",
        "            # metric_pce structure: [s1q1, s2q1, ..., snq1, s1q2, s2q2, ...]\n",
        "            # Append the specific score for the current metric (ordered by Q then S)\n",
        "            facts_pce.append(f_score)\n",
        "            articles_pce.append(r_score)\n",
        "            analysis_pce.append(a_score)\n",
        "\n",
        "    return total_flat, facts_pce, articles_pce, analysis_pce\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6HAHJg9ZOUp"
      },
      "source": [
        "#### Meta-evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "d3c4HTuhV8Fg",
        "outputId": "7cb0f676-1da3-482c-94f9-bed5d0c60b60"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_spa_results_horizontal\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Judge\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4.1-2025-04-14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Facts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6266,\n        \"max\": 0.6266,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Articles\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6745,\n        \"max\": 0.6745,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Analysis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8344,\n        \"max\": 0.8344,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7064,\n        \"max\": 0.7064,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_spa_results_horizontal"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-848a24c9-f908-4f5d-89b1-5dc779e0cb88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Judge</th>\n",
              "      <th>Facts</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Analysis</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt-4.1-2025-04-14</td>\n",
              "      <td>0.6266</td>\n",
              "      <td>0.6745</td>\n",
              "      <td>0.8344</td>\n",
              "      <td>0.7064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-848a24c9-f908-4f5d-89b1-5dc779e0cb88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-848a24c9-f908-4f5d-89b1-5dc779e0cb88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-848a24c9-f908-4f5d-89b1-5dc779e0cb88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_bcb12a9e-282f-4dab-b7ec-b8abe7b240d5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_spa_results_horizontal')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bcb12a9e-282f-4dab-b7ec-b8abe7b240d5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_spa_results_horizontal');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Judge   Facts  Articles  Analysis   Total\n",
              "0  gpt-4.1-2025-04-14  0.6266    0.6745    0.8344  0.7064"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 1000\n",
        "systems = [\"gemini-2.0-flash-001\", \"o1-2024-12-17\", \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\", \"gpt-4o-2024-11-20\", \"us.deepseek.r1-v1:0\"]\n",
        "\n",
        "judge_total_scores, judge_facts_scores, judge_articles_scores, judge_analysis_scores = gather_scores_for_pce(systems, jme_judgements)\n",
        "\n",
        "annotators_total_scores, annotators_facts_scores, annotators_articles_scores, annotators_analysis_scores = gather_scores_for_pce(systems, subset_jme)\n",
        "\n",
        "num_systems = len(systems) # The number of systems being compared pairwise\n",
        "\n",
        "# Calculate SPA for each scoring dimension by comparing judge's scores to annotators' scores\n",
        "total_spa = PairwiseConfidenceError(annotators_total_scores, judge_total_scores, num_systems, N)[0]\n",
        "facts_spa = PairwiseConfidenceError(annotators_facts_scores, judge_facts_scores, num_systems, N)[0]\n",
        "articles_spa = PairwiseConfidenceError(annotators_articles_scores, judge_articles_scores, num_systems, N)[0]\n",
        "analysis_spa = PairwiseConfidenceError(annotators_analysis_scores, judge_analysis_scores, num_systems, N)[0]\n",
        "\n",
        "horizontal_spa_results_dict = {\n",
        "    \"Judge\": [JUDGE],\n",
        "    \"Facts\": [facts_spa],\n",
        "    \"Articles\": [articles_spa],\n",
        "    \"Analysis\": [analysis_spa],\n",
        "    \"Total\": [total_spa],\n",
        "\n",
        "}\n",
        "\n",
        "df_spa_results_horizontal = pd.DataFrame(\n",
        "    horizontal_spa_results_dict\n",
        ")\n",
        "\n",
        "df_spa_results_horizontal"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0210c050cf2f421f94bb82954d35320e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02f6f786916e48368dcf04d97fc5f5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04142b7c974b40e79cb0d0f057331657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f3bef95f2dd486a8a722433e5aee12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "104524f01b9d4a91a72b8b793a18ca37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10de49069aa646b9978d77098888c667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7eb9996355e47bc9ad9ed88e0c43607",
            "max": 549748,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f3bef95f2dd486a8a722433e5aee12c",
            "value": 549748
          }
        },
        "186cae6964374d02bb11c94a5ff3e5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6968ca52ae134781b5324e4213a23eac",
            "placeholder": "​",
            "style": "IPY_MODEL_4cf2416ef066433c8c1d5a29caa33f7a",
            "value": " 12.8k/12.8k [00:00&lt;00:00, 204kB/s]"
          }
        },
        "18f4a8ebe82d44f0a5c5f455c570c0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e031c3b1a1e42cd882338756798672a",
            "placeholder": "​",
            "style": "IPY_MODEL_fd5b12675a364b0f818a1f68f2cba9ad",
            "value": " 305/305 [00:00&lt;00:00, 1979.88 examples/s]"
          }
        },
        "1be3fb6ca88e4bc5b798161cd6db64a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c2a71e967da4a31b028a5bacd7aeccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d916953a94a47d1afa5f4288dfea2de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe837e49c8c41cd95d3a05e449b7f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1049d1de8654842893bb90d64517eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_444428351c5745bdaf08e6befdb6c3ce",
            "value": "README.md: 100%"
          }
        },
        "25ca18d7ae9540838d150d69c4516c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa1106e644645a5b44b1298fa1a15ad",
            "max": 284,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_104524f01b9d4a91a72b8b793a18ca37",
            "value": 284
          }
        },
        "2626bd6062524a2a824cab71845dc594": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2636ce18d084441ead825c9ba15bfad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b612c1130e84acfab646d679338c175",
            "placeholder": "​",
            "style": "IPY_MODEL_653de683a9434b8089bf43fb16f6ea64",
            "value": " 42.3M/42.3M [00:00&lt;00:00, 72.0MB/s]"
          }
        },
        "282ebaf88445402e8ad687142faf4530": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a665ed5a933d49b38643ca70aba528c1",
            "placeholder": "​",
            "style": "IPY_MODEL_aba6a08f5551468da21c7be8076e8a9e",
            "value": "Generating test split: 100%"
          }
        },
        "2a6a0ce78acb4e6398a70b9a4375e603": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b6e2505858452bba73c844a01f01ac",
            "placeholder": "​",
            "style": "IPY_MODEL_0210c050cf2f421f94bb82954d35320e",
            "value": " 284/284 [00:01&lt;00:00, 198.59 examples/s]"
          }
        },
        "2a6f434d7eda47d79b7f7804154b9b07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e031c3b1a1e42cd882338756798672a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bf0e5a3bd74096a375cd0defb0d601": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acd8e2671e9e4029927f66fa7acd04dc",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a1f21e3a1374441865cfa700b3978c9",
            "value": 305
          }
        },
        "3b4c76abeea6471ea09968ca2adcd15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3bd6c3ea64a4314aff196fdb761a5b6",
            "placeholder": "​",
            "style": "IPY_MODEL_b67007b85c014fd49f6b461b2ca11bef",
            "value": " 284/284 [00:00&lt;00:00, 807.87 examples/s]"
          }
        },
        "42a7d26b256f4e63b338ff007912186a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444428351c5745bdaf08e6befdb6c3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b612c1130e84acfab646d679338c175": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf2416ef066433c8c1d5a29caa33f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "505d83a88589498e9872aa1c43bc7fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e87fabea6284db6af2d847fcdd80aae",
              "IPY_MODEL_6d1cefe241954241806f58cc4628ef71",
              "IPY_MODEL_2636ce18d084441ead825c9ba15bfad8"
            ],
            "layout": "IPY_MODEL_6a67111c197f4d36837482fcd4781856"
          }
        },
        "52f45b9716a045beb3bbbb920f966f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85bd7728737640d397125452a866977b",
              "IPY_MODEL_a2eb79ed13ba458ebe3a42353ceb26bc",
              "IPY_MODEL_18f4a8ebe82d44f0a5c5f455c570c0d0"
            ],
            "layout": "IPY_MODEL_b2fb5de0e07f4951968cdd6bbb90fbfe"
          }
        },
        "53fad2f0b31446878a36847a7267aec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af195ff975647d3af6a7f27af74981e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61df6e4502ea4536b59346ecf3706bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62b6e2505858452bba73c844a01f01ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637ee256b0b44391965ebf2cef24b913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d081b6e1f94b54a2bd9c76cb735884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fe837e49c8c41cd95d3a05e449b7f7a",
              "IPY_MODEL_b247b600508245a3a39628ff97cf6a59",
              "IPY_MODEL_186cae6964374d02bb11c94a5ff3e5bd"
            ],
            "layout": "IPY_MODEL_2a6f434d7eda47d79b7f7804154b9b07"
          }
        },
        "653de683a9434b8089bf43fb16f6ea64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6968ca52ae134781b5324e4213a23eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a67111c197f4d36837482fcd4781856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a827bcceb3a46158a778c0a4e73b572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b6ec103022a412a8c40a3b4951d638d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1cefe241954241806f58cc4628ef71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6ec103022a412a8c40a3b4951d638d",
            "max": 42328340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02f6f786916e48368dcf04d97fc5f5d5",
            "value": 42328340
          }
        },
        "712e9233789e40e6bbb222e215e05724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "725c1de061ea438097c6729a027c90e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73d5735fe6974703a7af9af6f100412d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749214343d2b49b8b32b379cab78f8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2bfaa7299b4482e84bf2720f9e38f6a",
              "IPY_MODEL_39bf0e5a3bd74096a375cd0defb0d601",
              "IPY_MODEL_c159bfa746fb44069dcee6579d6be8a4"
            ],
            "layout": "IPY_MODEL_42a7d26b256f4e63b338ff007912186a"
          }
        },
        "771be62d864649d0ba3a57b838c2f7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a8e6d17327a46cd8c5601fd194b056a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4b6d8e7ecfd430580575ba2aa9efc33",
              "IPY_MODEL_b55f9f57f0a44d87b9e60ea6aabedf63",
              "IPY_MODEL_3b4c76abeea6471ea09968ca2adcd15b"
            ],
            "layout": "IPY_MODEL_2626bd6062524a2a824cab71845dc594"
          }
        },
        "7e87fabea6284db6af2d847fcdd80aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf63207595864d87b64b013660b51aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_1be3fb6ca88e4bc5b798161cd6db64a6",
            "value": "greekbarbench.csv: 100%"
          }
        },
        "829be2e58651453a926ed541551b8974": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843863b5c0a34939af2e71e9081dcc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "859f3bbfcc2c40349b9cabd04fcfc9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bd7728737640d397125452a866977b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d916953a94a47d1afa5f4288dfea2de",
            "placeholder": "​",
            "style": "IPY_MODEL_b472236705574f2cb3b93600a9075cfe",
            "value": "Generating test split: 100%"
          }
        },
        "8a1f21e3a1374441865cfa700b3978c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dafd2102440459eac5aac6162bdc833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c2a71e967da4a31b028a5bacd7aeccb",
            "placeholder": "​",
            "style": "IPY_MODEL_637ee256b0b44391965ebf2cef24b913",
            "value": "gbb_jme.csv: 100%"
          }
        },
        "99732519afeb44999a58d0306485fa47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a01709c4c9bc4ec0ac6230a821fb5628": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1049d1de8654842893bb90d64517eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2bfaa7299b4482e84bf2720f9e38f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d5735fe6974703a7af9af6f100412d",
            "placeholder": "​",
            "style": "IPY_MODEL_61df6e4502ea4536b59346ecf3706bb9",
            "value": "Filter: 100%"
          }
        },
        "a2eb79ed13ba458ebe3a42353ceb26bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a827bcceb3a46158a778c0a4e73b572",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_712e9233789e40e6bbb222e215e05724",
            "value": 305
          }
        },
        "a665ed5a933d49b38643ca70aba528c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba6a08f5551468da21c7be8076e8a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acd8e2671e9e4029927f66fa7acd04dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b247b600508245a3a39628ff97cf6a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdccff244681431581b4dbebc0b3f6dc",
            "max": 12805,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99732519afeb44999a58d0306485fa47",
            "value": 12805
          }
        },
        "b2fb5de0e07f4951968cdd6bbb90fbfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b472236705574f2cb3b93600a9075cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b55f9f57f0a44d87b9e60ea6aabedf63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c772c8ede78e40a292d8b08be6e4f94b",
            "max": 284,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_725c1de061ea438097c6729a027c90e5",
            "value": 284
          }
        },
        "b67007b85c014fd49f6b461b2ca11bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6d710b119bb43e292ad888f2e75bad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dafd2102440459eac5aac6162bdc833",
              "IPY_MODEL_10de49069aa646b9978d77098888c667",
              "IPY_MODEL_cbbde9167054420ab6bf01ed3f4016df"
            ],
            "layout": "IPY_MODEL_5af195ff975647d3af6a7f27af74981e"
          }
        },
        "bf63207595864d87b64b013660b51aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa1106e644645a5b44b1298fa1a15ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c159bfa746fb44069dcee6579d6be8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53fad2f0b31446878a36847a7267aec9",
            "placeholder": "​",
            "style": "IPY_MODEL_771be62d864649d0ba3a57b838c2f7cf",
            "value": " 305/305 [00:00&lt;00:00, 8197.30 examples/s]"
          }
        },
        "c4b6d8e7ecfd430580575ba2aa9efc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_829be2e58651453a926ed541551b8974",
            "placeholder": "​",
            "style": "IPY_MODEL_843863b5c0a34939af2e71e9081dcc2d",
            "value": "Filter: 100%"
          }
        },
        "c772c8ede78e40a292d8b08be6e4f94b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7eb9996355e47bc9ad9ed88e0c43607": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbbde9167054420ab6bf01ed3f4016df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a01709c4c9bc4ec0ac6230a821fb5628",
            "placeholder": "​",
            "style": "IPY_MODEL_04142b7c974b40e79cb0d0f057331657",
            "value": " 550k/550k [00:00&lt;00:00, 4.09MB/s]"
          }
        },
        "cdccff244681431581b4dbebc0b3f6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3bd6c3ea64a4314aff196fdb761a5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e599952fa7774330a1c6b804c0f9eb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_282ebaf88445402e8ad687142faf4530",
              "IPY_MODEL_25ca18d7ae9540838d150d69c4516c67",
              "IPY_MODEL_2a6a0ce78acb4e6398a70b9a4375e603"
            ],
            "layout": "IPY_MODEL_859f3bbfcc2c40349b9cabd04fcfc9f6"
          }
        },
        "fd5b12675a364b0f818a1f68f2cba9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
